{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a572ed03",
   "metadata": {},
   "source": [
    "# AV leader classifier (applied to Lyft only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28822c-8d64-4fa0-979b-c503d304b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' # use this if matplotlib does not work\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "parent_dir = os.path.abspath('..') # Set your parent directory here.\n",
    "                               # Without change the current setting is the parent directory of this file.\n",
    "inputdata_path = parent_dir + 'Data path example/OutputData/AV leader/data/'\n",
    "outputdata_path = parent_dir + 'Data path example/OutputData/AV leader/results_lstm/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e27137-8e52-417f-a54c-d68f2fce5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = 131\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f161a",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(inputdata_path):\n",
    "\n",
    "    traindata = pd.read_hdf(inputdata_path + 'data_train_HAandHH.h5', key='data')\n",
    "    trainlabels = pd.read_hdf(inputdata_path + 'label_train_HAandHH.h5', key='label')\n",
    "    valdata = pd.read_hdf(inputdata_path + 'data_val_HAandHH.h5', key='data')\n",
    "    vallabels = pd.read_hdf(inputdata_path + 'label_val_HAandHH.h5', key='label')\n",
    "    testdata = pd.read_hdf(inputdata_path + 'data_test_AHonly.h5', key='data')\n",
    "    testlabels = pd.read_hdf(inputdata_path + 'label_test_AHonly.h5', key='label')\n",
    "\n",
    "    return traindata, trainlabels, valdata, vallabels, testdata, testlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72752148",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata, trainlabels, valdata, vallabels, testdata, testlabels = read_data(inputdata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('traindata,', 'HH case num:', traindata[traindata['label']<0.5]['case_id'].nunique(), 'HA case num:', traindata[traindata['label']>0.5]['case_id'].nunique())\n",
    "print('traindata,', 'HH subcase num:', traindata[traindata['label']<0.5]['new_id'].nunique(), 'HA subcase num:', traindata[traindata['label']>0.5]['new_id'].nunique())\n",
    "print('valdata,', 'HH case num:', valdata[valdata['label']<0.5]['case_id'].nunique(), 'HA case num:', valdata[valdata['label']>0.5]['case_id'].nunique())\n",
    "print('valdata,', 'HH subcase num:', valdata[valdata['label']<0.5]['new_id'].nunique(), 'HA subcase num:', valdata[valdata['label']>0.5]['new_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(8,1.5))\n",
    "\n",
    "traindata[traindata['label']<0.5].groupby('case_id')['v_leader'].max().hist(alpha=0.5, bins=np.linspace(0,1,30), ax=axes[0])\n",
    "traindata[traindata['label']>0.5].groupby('case_id')['v_leader'].max().hist(alpha=0.5, bins=np.linspace(0,1,30), ax=axes[0])\n",
    "\n",
    "_=axes[1].hist(traindata[traindata['label']<0.5].groupby('case_id').agg({'a_leader':['max','min']}).values.flatten(),alpha=0.5, bins=np.linspace(-6,6,30))\n",
    "_=axes[1].hist(traindata[traindata['label']>0.5].groupby('case_id').agg({'a_leader':['max','min']}).values.flatten(),alpha=0.5, bins=np.linspace(-6,6,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ca01d",
   "metadata": {},
   "source": [
    "## Create iterative datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset:\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = labels['label'].values\n",
    "        self.new_ids = labels['new_id'].values\n",
    "        self.data = data.sort_values(['new_id','time']).set_index('new_id')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.new_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # idx is the index of items in the data\n",
    "        new_id = self.new_ids[idx]\n",
    "        features = self.data.loc[new_id][['v_leader','a_leader']].values\n",
    "        features = torch.from_numpy(features).float()\n",
    "        label = self.labels[idx]\n",
    "        return features, label, new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc97a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(CreateDataset(traindata, trainlabels), batch_size=64, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(CreateDataset(testdata, testlabels), batch_size=64, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(CreateDataset(valdata, vallabels), batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, new_id = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "print(f\"Number of batches: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a81494",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8224ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(2, 64, 2, batch_first=True)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        h, (h_n, h_c) = self.lstm(x)\n",
    "        out = self.out(h_n[:-1:])\n",
    "        \n",
    "        return out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel().to(device)\n",
    "print(model)\n",
    "loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84546a7b",
   "metadata": {},
   "source": [
    "## Trainning and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1440e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_func, optimizer):\n",
    "    # size = len(dataloader.dataset)\n",
    "    loss_record = []\n",
    "    progress_bar = tqdm(enumerate(dataloader, 0), unit=\"batch\", total=len(dataloader))\n",
    "    for batch, (features, label, new_id) in progress_bar:\n",
    "        features, label = features.to(device), label.unsqueeze(1).float().to(device)\n",
    "        pred = model(features)\n",
    "        loss = loss_func(pred, label)\n",
    "        loss_record.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item(), refresh=False)\n",
    "\n",
    "    return loss_record\n",
    "\n",
    "\n",
    "def val_loop(dataloader, model, loss_func):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(dataloader, 0), unit=\"batch\", total=len(dataloader))\n",
    "        for batch, (features, label, new_id) in progress_bar:\n",
    "            features, label = features.to(device), label.unsqueeze(1).float().to(device)\n",
    "            pred = model(features)\n",
    "            val_loss += loss_func(pred, label).item()\n",
    "            correct += (pred.ge(0.5).float() == label).type(torch.float).sum().item()\n",
    "\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    return correct, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 240\n",
    "loss_records = np.zeros((epochs,len(train_dataloader)))*np.nan\n",
    "# loss_records = np.concatenate((loss_records, np.zeros((20,len(train_dataloader)))*np.nan))\n",
    "correct, t = 0, 0\n",
    "lr = 0.001\n",
    "while t<epochs:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, amsgrad=True)\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_record = train_loop(train_dataloader, model, loss_func, optimizer)\n",
    "    loss_records[t,:] = loss_record\n",
    "    t += 1\n",
    "\n",
    "    if t in np.arange(5,epochs+5,5):\n",
    "        torch.save(model.state_dict(), outputdata_path+'Leader classification_lstm_'+str(t)+'epoches.pth')\n",
    "        lr *= 0.95\n",
    "\n",
    "    if t%5 == 0:\n",
    "        correct, val_loss = val_loop(val_dataloader, model, loss_func)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Current validataion error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")\n",
    "\n",
    "pd.DataFrame(loss_records).to_csv(outputdata_path+'loss_records.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(test_dataloader.dataset)\n",
    "num_batches = len(test_dataloader)\n",
    "val_loss, correct = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress_bar = tqdm(enumerate(test_dataloader, 0), unit=\"batch\", total=len(test_dataloader))\n",
    "    for batch, (features, label, new_id) in progress_bar:\n",
    "        features, label = features.to(device), label.unsqueeze(1).float().to(device)\n",
    "        pred = model(features)\n",
    "        val_loss += loss_func(pred, label).item()\n",
    "        correct += (pred.ge(0.5).float() == label).type(torch.float).sum().item()\n",
    "val_loss /= num_batches\n",
    "correct /= size\n",
    "print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c2adec",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9245e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5,1.5),constrained_layout=True)\n",
    "loss_records = pd.read_csv(outputdata_path+'loss_records.csv')\n",
    "\n",
    "# loss_records = loss_records.values.reshape((40*11,43))\n",
    "loss = loss_records[~np.isnan(loss_records)]\n",
    "epoch = np.arange(0,loss_records.shape[0])\n",
    "ax.plot(epoch,loss_records.mean(axis=1),lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = []\n",
    "\n",
    "for num_epoches in tqdm(np.arange(5,epochs+5,5)):\n",
    "    model.load_state_dict(torch.load(outputdata_path+'Leader classification_lstm_'+str(num_epoches)+'epoches.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    confusion_matrix = pd.DataFrame(np.zeros((3,5)), index=['train','val','test'], columns=['TP','TN','FP','FN','size'])\n",
    "    for data_loader, setname in zip([train_dataloader, val_dataloader, test_dataloader], ['train', 'val', 'test']):\n",
    "        size = len(data_loader.dataset)\n",
    "        num_batches = len(data_loader)\n",
    "        true_positive, true_negative, false_positive, false_negative = 0, 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            progress_bar = enumerate(data_loader, 0)\n",
    "            for batch, (features, label, new_id) in progress_bar:\n",
    "                features, label = features.to(device), label.unsqueeze(1).float().to(device)\n",
    "                pred = model(features)\n",
    "                true_positive += ((pred.ge(0.5).float() == label)&(label > 0.5)).type(torch.float).sum().item()\n",
    "                true_negative += ((pred.ge(0.5).float() == label)&(label < 0.5)).type(torch.float).sum().item()\n",
    "                false_positive += ((pred.ge(0.5).float() != label)&(label < 0.5)).type(torch.float).sum().item()\n",
    "                false_negative += ((pred.ge(0.5).float() != label)&(label > 0.5)).type(torch.float).sum().item()\n",
    "        confusion_matrix.loc[setname,['TP','TN','FP','FN','size']] = np.array([true_positive,true_negative,false_positive,false_negative,size])\n",
    "\n",
    "    confusion_matrix['num_epoches'] = num_epoches\n",
    "    confusion_matrices.append(confusion_matrix)\n",
    "\n",
    "confusion_matrices = pd.concat(confusion_matrices).reset_index()\n",
    "confusion_matrices.to_csv(outputdata_path+'confusion_matrices.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(confusion_matrices):\n",
    "    confusion_matrices['accuracy'] = (confusion_matrices['TP']+confusion_matrices['TN'])/confusion_matrices['size']\n",
    "    confusion_matrices['precision'] = confusion_matrices['TP']/(confusion_matrices['TP']+confusion_matrices['FP'])\n",
    "    confusion_matrices['recall'] = confusion_matrices['TP']/(confusion_matrices['TP']+confusion_matrices['FN'])\n",
    "    confusion_matrices['F1'] = 2*confusion_matrices['precision']*confusion_matrices['recall']/(confusion_matrices['precision']+confusion_matrices['recall'])\n",
    "    fig, axes = plt.subplots(1,3,figsize=(7.5,4.5),constrained_layout=True)\n",
    "    loss_records = pd.read_csv(outputdata_path+'loss_records.csv')\n",
    "    axes[0].plot(loss_records.index+1,loss_records.mean(axis=1),lw=1,c=(0,0,0,0.8))\n",
    "    loss_records = loss_records.loc[np.arange(5,epochs+5,5)-1]\n",
    "    axes[0].scatter(loss_records.index+1,loss_records.mean(axis=1),s=20,color=(0,0,0,1),lw=1,marker='x')\n",
    "    colors = [(0,0,1,0.8),(0,0.5,0,0.8),(1,0,0,0.5)]\n",
    "    for index,col in zip(['train','val','test'],colors):\n",
    "        confusion_matrix = confusion_matrices[confusion_matrices['index']==index]\n",
    "        axes[1].plot(confusion_matrix['num_epoches'], confusion_matrix['accuracy'], c=col, lw=1, marker='x', markersize=5, label='Precision')\n",
    "        axes[2].plot(confusion_matrix['num_epoches'], confusion_matrix['F1'], c=col, lw=1, marker='x', markersize=5, label='F1')\n",
    "    axes[0].set_title('Average loss', fontsize=8)\n",
    "    axes[1].set_title('Accuracy', fontsize=8)\n",
    "    axes[2].set_title('F1 score', fontsize=8)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    handles, _ = axes[1].get_legend_handles_labels()\n",
    "    axes[2].legend([handles[0], handles[1], handles[2]], \n",
    "                   ['Train','Val.','Test'], \n",
    "                   frameon=False, ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.05))\n",
    "    \n",
    "    for ax in [axes[1],axes[2]]:\n",
    "        for pos in [10,85,145]:\n",
    "            ax.plot([pos,pos],[0.4,0.95])\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797d980",
   "metadata": {},
   "source": [
    "## Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(dataloader, 0), unit=\"batch\", total=len(dataloader))\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        new_ids = []\n",
    "        for batch, (features, label, new_id) in progress_bar:\n",
    "            features, label = features.to(device), label.unsqueeze(1).float().to(device)\n",
    "            pred = model(features)\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "            new_ids.append(new_id)\n",
    "\n",
    "    predictions = torch.cat(predictions, dim=0)\n",
    "    results = pd.DataFrame({'new_id':torch.cat(new_ids, dim=0).cpu().numpy().flatten(),\n",
    "                            'label':torch.cat(labels, dim=0).cpu().numpy().flatten(),\n",
    "                            'prediction':predictions.cpu().numpy().flatten()})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(outputdata_path+'Leader classification_lstm_145epoches.pth', map_location=torch.device('cpu')))\n",
    "model.load_state_dict(torch.load(outputdata_path+'Leader classification_lstm_145epoches.pth'))\n",
    "model.eval()\n",
    "results_train = get_predictions(train_dataloader, model)\n",
    "results_train.to_csv(outputdata_path+'prediction_train.csv', index=False)\n",
    "print(results_train[results_train['prediction']<0.5]['new_id'].nunique()/len(results_train))\n",
    "results_val = get_predictions(val_dataloader, model)\n",
    "results_val.to_csv(outputdata_path+'prediction_val.csv', index=False)\n",
    "print(results_val[results_val['prediction']<0.5]['new_id'].nunique()/len(results_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in tqdm([10,85,145,200]):\n",
    "    model.load_state_dict(torch.load(outputdata_path+'Leader classification_lstm_'+str(pos)+'epoches.pth', map_location=torch.device('cpu')))\n",
    "    # model.load_state_dict(torch.load(outputdata_path+'Leader classification_lstm_'+str(pos)+'epoches.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    std_list = np.arange(0,0.1,0.0005)\n",
    "    pred_list = []\n",
    "    for std in std_list:\n",
    "        features = np.random.normal(0,std,148*2).reshape((1,148,2))\n",
    "        features = torch.from_numpy(features).float().to(device)\n",
    "        pred_list.append(model(features).item())\n",
    "\n",
    "    zero_test = pd.DataFrame({'std':std_list,'pred':pred_list})\n",
    "    zero_test.to_csv(outputdata_path+'zero_test'+str(pos)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
