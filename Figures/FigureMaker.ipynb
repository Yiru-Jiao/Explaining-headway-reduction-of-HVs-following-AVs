{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headway analysis and figure making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as systime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import binned_statistic_2d, ks_2samp, binned_statistic, gaussian_kde\n",
    "plt.rcParams[\"font.family\"] = 'Arial'\n",
    "plt.style.use('default')\n",
    "font = {'family' : 'Arial', 'size'   : 8}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "from tqdm import tqdm\n",
    "\n",
    "import visual_utils as vis\n",
    "\n",
    "figure_path = r'C:/SURFdrive/PhD progress/PhDResearch/3_AVCF/PartC/Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cfpair, dataset):\n",
    "    data = pd.read_hdf('../Data/InputData/'+dataset+'/CFdata/'+cfpair+'.h5', key='data').reset_index(drop=True)\n",
    "    regimes = pd.read_hdf('../Data/OutputData/CF regime/'+dataset+'/regimes/regimes_all_'+cfpair+'.h5', key='regimes')\n",
    "    data = data.merge(regimes, on=['case_id','time'], how='left')\n",
    "\n",
    "    # correct negative speeds due to filtering\n",
    "    data.loc[(data['v_follower']<0),'v_follower'] = 0.\n",
    "    data.loc[(data['v_leader']<0),'v_leader'] = 0.\n",
    "\n",
    "    data['dhw'] = data['x_leader'] - data['x_follower']\n",
    "    data['thw'] = data['dhw']/data['v_follower']\n",
    "    data.loc[np.isinf(data['thw']),'thw'] = np.nan\n",
    "    \n",
    "    return data   \n",
    "\n",
    "Waymo_AH = read_data('AH', 'Waymo')\n",
    "Waymo_HA = read_data('HA', 'Waymo')\n",
    "Waymo_HH = read_data('HH', 'Waymo')\n",
    "Lyft_AH = read_data('AH', 'Lyft')\n",
    "Lyft_HA = read_data('HA', 'Lyft')\n",
    "Lyft_HH = read_data('HH', 'Lyft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lyft:')\n",
    "print('AH train min duration:', Lyft_AH.groupby('case_id').time.count().min()/10)\n",
    "print('HA train min duration:', Lyft_HA.groupby('case_id').time.count().min()/10)\n",
    "print('HH train min duration:', Lyft_HH.groupby('case_id').time.count().min()/10)\n",
    "print('Waymo:')\n",
    "print('AH train min duration:', Waymo_AH.groupby('case_id').time.count().min()/10)\n",
    "print('HA train min duration:', Waymo_HA.groupby('case_id').time.count().min()/10)\n",
    "print('HH train min duration:', Waymo_HH.groupby('case_id').time.count().min()/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waymo\n",
    "dataset_description = pd.DataFrame({'dataset':['Waymo_AH','Waymo_HA','Waymo_HH']})\n",
    "dataset_description = dataset_description.set_index('dataset')\n",
    "for data, setname in zip([Waymo_AH, Waymo_HA, Waymo_HH],['Waymo_AH','Waymo_HA','Waymo_HH']):\n",
    "    test = data.groupby('case_id').agg({'v_follower':['min','max'],'v_leader':['min','max'], 'time':'max'})\n",
    "    dataset_description.loc[setname,'num cases'] = len(test)\n",
    "    # valid cases should have diverse car-following states\n",
    "    valid_cases = test[(test['v_follower']['min']<0.1)&\n",
    "                       (test['v_leader']['min']<0.1)&\n",
    "                       (test['v_follower']['max']>=10)]\n",
    "    dataset_description.loc[setname,'num valid cases'] = len(valid_cases)\n",
    "    dataset_description.loc[setname,'average duration of valid cases'] = valid_cases['time']['max'].mean()\n",
    "\n",
    "dataset_description.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyft\n",
    "dataset_description = pd.DataFrame({'dataset':['Lyft_AH','Lyft_HA','Lyft_HH']})\n",
    "dataset_description = dataset_description.set_index('dataset')\n",
    "for data, setname in zip([Lyft_AH, Lyft_HA, Lyft_HH],['Lyft_AH','Lyft_HA','Lyft_HH']):\n",
    "    test = data.groupby('case_id').agg({'v_follower':['min','max'],'v_leader':['min','max'], 'time':'max'})\n",
    "    dataset_description.loc[setname,'num cases'] = len(test)\n",
    "    # valid cases should have diverse car-following states\n",
    "    valid_cases = test[(test['v_follower']['min']<0.1)&\n",
    "                       (test['v_leader']['min']<0.1)&\n",
    "                       (test['v_follower']['max']>=10)]\n",
    "    dataset_description.loc[setname,'num valid cases'] = len(valid_cases)\n",
    "    dataset_description.loc[setname,'average max. speed in valid cases'] = valid_cases['time']['max'].mean()\n",
    "\n",
    "dataset_description.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lyft overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.compare_HH_HA(Lyft_HH, Lyft_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'HH_HA_va.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Sensor error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Length distribution\n",
    "Unsure the influence of sensor error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.length_dist(Waymo_HH,\n",
    "                            Waymo_HA, 'Waymo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'length_dist_waymo.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.length_impact(Waymo_HH[(Waymo_HH['v_leader']<0.1)&(Waymo_HH['v_follower']<0.1)],\n",
    "                              Waymo_HA[(Waymo_HA['v_leader']<0.1)&(Waymo_HA['v_follower']<0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'length_impact_waymo.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.length_dist(Lyft_HH,\n",
    "                            Lyft_HA, 'Lyft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'length_dist_lyft.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.length_impact(Lyft_HH[(Lyft_HH['v_leader']<0.1)&(Lyft_HH['v_follower']<0.1)],\n",
    "                              Lyft_HA[(Lyft_HA['v_leader']<0.1)&(Lyft_HA['v_follower']<0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'length_impact_lyft.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfdata_HH = Lyft_HH[(Lyft_HH['v_leader']<0.1)&(Lyft_HH['v_follower']<0.1)]\n",
    "cfdata_HH = cfdata_HH.groupby('case_id')[['l_follower','l_leader']].first()\n",
    "cfdata_HA = Lyft_HA[(Lyft_HA['v_leader']<0.1)&(Lyft_HA['v_follower']<0.1)]\n",
    "cfdata_HA = cfdata_HA.groupby('case_id')[['l_follower','l_leader']].first()\n",
    "length_HH = (cfdata_HH.l_follower + cfdata_HH.l_leader).mean()\n",
    "length_HA = (cfdata_HA.l_follower + cfdata_HA.l_leader).mean()\n",
    "print('Lyft impacts on gap', length_HA, length_HH, length_HA-length_HH)\n",
    "\n",
    "cfdata_HH = Waymo_HH[(Waymo_HH['v_leader']<0.1)&(Waymo_HH['v_follower']<0.1)]\n",
    "cfdata_HH = cfdata_HH.groupby('case_id')[['l_follower','l_leader']].first()\n",
    "cfdata_HA = Waymo_HA[(Waymo_HA['v_leader']<0.1)&(Waymo_HA['v_follower']<0.1)]\n",
    "cfdata_HA = cfdata_HA.groupby('case_id')[['l_follower','l_leader']].first()\n",
    "length_HH = (cfdata_HH.l_follower + cfdata_HH.l_leader).mean()\n",
    "length_HA = (cfdata_HA.l_follower + cfdata_HA.l_leader).mean()\n",
    "print('Waymo impacts on gap', length_HA, length_HH, length_HA-length_HH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Min. distance and time headway (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.headway_dist(Waymo_HH,Waymo_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.headway_dist(Lyft_HH,Lyft_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'headway_dist_original.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 CF regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_regime_id(cfdata):\n",
    "    cfdata = cfdata.copy()\n",
    "    regime_indices = cfdata[['case_id','time','regime']].sort_values(by=['case_id','time']).reset_index().set_index('case_id')\n",
    "    cfdata['regime_id'] = np.zeros(len(cfdata)).astype(int)\n",
    "    cfdata['regime_duration'] = np.zeros(len(cfdata))\n",
    "    regime_id = 1\n",
    "    for caseid in tqdm(regime_indices.index.unique()):\n",
    "        cfdf = regime_indices.loc[caseid]\n",
    "        end_list = np.where(cfdf.iloc[1:]['regime'].values!=cfdf.iloc[:-1]['regime'].values)[0]\n",
    "        start_list = end_list + 1\n",
    "        start_list = np.append(0,start_list)\n",
    "        end_list = np.append(end_list,len(cfdf)-1)\n",
    "        end_list = end_list + 1\n",
    "        for start,end in zip(start_list,end_list):\n",
    "            cfdata.loc[cfdf['index'].values[start:end],'regime_duration'] = (end-start)*0.1\n",
    "            if end-start<5:\n",
    "                cfdata.loc[cfdf['index'].values[start:end],'regime_id'] = 0\n",
    "            else:\n",
    "                cfdata.loc[cfdf['index'].values[start:end],'regime_id'] = regime_id\n",
    "                regime_id += 1\n",
    "    return cfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lyft_HA = assign_regime_id(Lyft_HA)\n",
    "Lyft_HH = assign_regime_id(Lyft_HH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Regime distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.regime_example(Lyft_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(figure_path+'regime_example.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regime_list_HA = pd.read_csv(r'U:/Vehicle Coordination Yiru/OutputData/CFAV/headway/CF regime/Lyft/regimes/regimes_list_HA.csv')\n",
    "regime_list_HH = pd.read_csv(r'U:/Vehicle Coordination Yiru/OutputData/CFAV/headway/CF regime/Lyft/regimes/regimes_list_HH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = vis.regime_proportion(regime_list_HA, regime_list_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'regime_proportion.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thw HH\n",
    "thw_HH = Lyft_HH.loc[Lyft_HH.groupby('case_id')['thw'].idxmin()].groupby('regime').agg({'time':'count','thw':'mean'})\n",
    "thw_HH['time'] = thw_HH['time']/thw_HH['time'].sum()*100\n",
    "thw_HH.loc[['Fa','C','Fd','D','A','F']].T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thw HA\n",
    "thw_HA = Lyft_HA.loc[Lyft_HA.groupby('case_id')['thw'].idxmin()].groupby('regime').agg({'time':'count','thw':'mean'})\n",
    "thw_HA['time'] = thw_HA['time']/thw_HA['time'].sum()*100\n",
    "thw_HA.loc[['Fa','C','Fd','D','A','F']].T.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.headway_dist_regime(Lyft_HH, Lyft_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'headway_dist_regime.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Leading vehicle variability effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cfpair,model,incul_data=False,data_path='../Data/OutputData/Variability/'):\n",
    "    parameters = pd.read_csv(data_path+model+'/parameters_Lyft_'+cfpair+'.csv', index_col=0)\n",
    "    parameters = parameters.dropna()\n",
    "\n",
    "    loss = pd.read_csv(data_path+model+'/loss_Lyft_'+cfpair+'.csv', index_col=0)\n",
    "    loss = loss.loc[parameters.index]\n",
    "\n",
    "    if incul_data:\n",
    "        data = pd.read_hdf(data_path+'cfdata_idm_Lyft_'+cfpair+'.h5', key='data')\n",
    "        data['dhw'] = data['x_leader'] - data['x_follower'] - data['l_follower']/2 + data['l_leader']/2\n",
    "        data['thw'] = data['dhw'] / data['v_follower']\n",
    "\n",
    "    return (data, parameters, loss) if incul_data else (parameters, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 IDM parameter comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_HA, idm_HA, loss_HA = read_data('HA', 'idm', incul_data=True)\n",
    "data_HH, idm_HH, loss_HH = read_data('HH', 'idm', incul_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only non-zero compared\n",
    "loss_HH.dropna().agg(['count','mean','std']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only non-zero compared\n",
    "loss_HA.dropna().agg(['count','mean','std']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.idm_parameters(idm_HH,idm_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'idm_parameters.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gipps parameter comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_HA, gipps_HA, loss_HA = read_data('HA', 'gipps', incul_data=True)\n",
    "data_HH, gipps_HH, loss_HH = read_data('HH', 'gipps', incul_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only non-zero compared\n",
    "loss_HH.dropna().agg(['count','mean','std']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only non-zero compared\n",
    "loss_HA.dropna().agg(['count','mean','std']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.gipps_parameters(gipps_HH,gipps_HA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'gipps_parameters.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cross following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_crossfollow(cfpair, model):\n",
    "    data = pd.read_hdf('../Data/OutputData/Variability/crossfollow/'+model+'/crossfollow_Lyft_'+cfpair+'.h5', key='data')\n",
    "    regimes = pd.read_hdf('../Data/OutputData/Variability/regime_simulated/'+model+'_simulated/regimes/regimes_all_'+cfpair+'.h5', key='regimes')\n",
    "    data = data.merge(regimes, on=['case_id','time'], how='left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 IDM simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thwHH = [1,1,1,1]\n",
    "thwHA = [-0.9,-0.7,-0.95,-0.9]\n",
    "binHH = [0.1,0.1,0.1,0.1]\n",
    "binHA = [0.15,0.15,0.15,0.15]\n",
    "for count in [0,1,2,3]:\n",
    "    fHH_lHHhigherVar = read_data_crossfollow('fHH_lHHhigherVar_'+str(count), 'idm')\n",
    "    fHH_lHHlowerVar = read_data_crossfollow('fHH_lHHlowerVar_'+str(count), 'idm')\n",
    "    fig, axes = vis.headway_leader_variability(fHH_lHHhigherVar, fHH_lHHlowerVar, thwHH[count], thwHA[count], binHH[count], binHA[count])\n",
    "    fig.savefig(figure_path+'headway_leader_variability_'+str(count)+'.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Gipps simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thwHH = [0.9,0.9,0.9,1]\n",
    "thwHA = [-0.9,-0.5,-0.85,-0.95]\n",
    "binHH = [0.1,0.1,0.1,0.1]\n",
    "binHA = [0.15,0.15,0.15,0.15]\n",
    "for count in [0,1,2,3]:\n",
    "    fHH_lHHhigherVar = read_data_crossfollow('fHH_lHHhigherVar_'+str(count), 'gipps')\n",
    "    fHH_lHHlowerVar = read_data_crossfollow('fHH_lHHlowerVar_'+str(count), 'gipps')\n",
    "    fig, axes = vis.headway_leader_variability(fHH_lHHhigherVar, fHH_lHHlowerVar, thwHH[count], thwHA[count], binHH[count], binHA[count])\n",
    "    fig.savefig(figure_path+'gipps_headway_leader_variability_'+str(count)+'.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 AV dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traindata, HH case num: 15111 HA case num: 13813\n",
    "\n",
    "traindata, HH subcase num: 30246 HA subcase num: 30257\n",
    "\n",
    "valdata, HH case num: 15112 HA case num: 13814\n",
    "\n",
    "valdata, HH subcase num: 30241 HA subcase num: 30199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdata_path = r'U:/Vehicle Coordination Yiru/OutputData/CFAV/headway/AV leader/data/'\n",
    "outputdata_path = r'U:/Vehicle Coordination Yiru/OutputData/CFAV/headway/AV leader/results_lstm/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = pd.read_csv(outputdata_path+'confusion_matrices.csv')\n",
    "loss_records = pd.read_csv(outputdata_path+'loss_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.evaluate_classifier(confusion_matrices[confusion_matrices['num_epoches']<205].copy(),loss_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'classifier_evaluation.pdf',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tests = []\n",
    "for epoch in [10,85,145,200]:\n",
    "    zero_test = pd.read_csv(outputdata_path+'zero_test'+str(epoch)+'.csv')\n",
    "    zero_tests.append(zero_test)\n",
    "\n",
    "fig, axes = vis.scatter_zero_test(zero_tests, [10,85,145,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'static_state_test.pdf',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: AV leader, 0: HV leader\n",
    "def read_classified_data(setname):\n",
    "    data_HAandHH = pd.read_hdf(inputdata_path+'data_'+setname+'_HAandHH.h5', key='data')\n",
    "    label_HAandHH = pd.read_hdf(inputdata_path+'label_'+setname+'_HAandHH.h5', key='label')\n",
    "    pred_HAandHH = pd.read_csv(outputdata_path+'prediction_'+setname+'.csv')\n",
    "\n",
    "    label_HAandHH['prediction'] = pred_HAandHH.set_index('new_id').loc[label_HAandHH['new_id'].values]['prediction'].values\n",
    "    pred_HAandHH = data_HAandHH[['label','new_id','case_id','subcase','time']].copy()\n",
    "    pred_HAandHH['pred'] = label_HAandHH.set_index(['new_id']).loc[data_HAandHH['new_id'].values]['prediction'].values\n",
    "\n",
    "    data_HAandHH = data_HAandHH.drop_duplicates(subset=['case_id','time']).drop(columns=['subcase'])\n",
    "    aggregation = pred_HAandHH.groupby(['label','case_id','time'])['pred'].mean().reset_index().set_index(['label','case_id','time'])\n",
    "    data_HAandHH['pred_time'] = aggregation.reindex(pd.MultiIndex.from_frame(data_HAandHH[['label','case_id','time']])).values\n",
    "    aggregation = pred_HAandHH.groupby(['label','case_id'])['pred'].mean().reset_index().set_index(['label','case_id'])\n",
    "    data_HAandHH['pred_case'] = aggregation.reindex(pd.MultiIndex.from_frame(data_HAandHH[['label','case_id']])).values\n",
    "\n",
    "    HA = data_HAandHH[(data_HAandHH['label']>0.5)].copy()\n",
    "    HA[['v_leader','a_leader','v_follower','dhw','thw']] = Lyft_HA.set_index(['case_id','time']).reindex(pd.MultiIndex.from_frame(HA[['case_id','time']]))[['v_leader','a_leader','v_follower','dhw','thw']].values\n",
    "    HA['regime'] = Lyft_HA.set_index(['case_id','time']).reindex(pd.MultiIndex.from_frame(HA[['case_id','time']]))['regime'].values\n",
    "    HH = data_HAandHH[(data_HAandHH['label']<0.5)].copy()\n",
    "    HH[['v_leader','a_leader','v_follower','dhw','thw']] = Lyft_HH.set_index(['case_id','time']).reindex(pd.MultiIndex.from_frame(HH[['case_id','time']]))[['v_leader','a_leader','v_follower','dhw','thw']].values\n",
    "    HH['regime'] = Lyft_HH.set_index(['case_id','time']).reindex(pd.MultiIndex.from_frame(HH[['case_id','time']]))['regime'].values\n",
    "\n",
    "    return HA, HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_HA, train_HH = read_classified_data('train')\n",
    "val_HA, val_HH = read_classified_data('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In validation set:')\n",
    "print('Num of HA leaders classified as HV', val_HA[val_HA['pred_case']<0.5]['case_id'].nunique())\n",
    "print('Num of HA leaders classified as AV', val_HA[val_HA['pred_case']>0.5]['case_id'].nunique())\n",
    "print('Num of HH leaders classified as HV', val_HH[val_HH['pred_case']<0.5]['case_id'].nunique())\n",
    "print('Num of HH leaders classified as AV', val_HH[val_HH['pred_case']>0.5]['case_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.compare_leader(val_HA[val_HA['pred_case']<=0.5], val_HA[val_HA['pred_case']>0.5], Lyft_HH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'compare_leader.pdf',dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.headway_dist_dynamics(val_HA, 'pred_case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'headway_dist_dynamics_case.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = vis.headway_dist_dynamics(val_HA, 'pred_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'headway_dist_dynamics_time.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Discussion: THW to DHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r'U:/Vehicle Coordination Yiru/OutputData/CFAV/headway/CF regime/'\n",
    "regime_list_HH = pd.read_csv(output_path+'Lyft/regimes/regimes_list_HH.csv', index_col=0)\n",
    "regime_list_HA = pd.read_csv(output_path+'Lyft/regimes/regimes_list_HA.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_deceleration(cfdata, regime_list):\n",
    "    cfdata = cfdata.sort_values(by=['case_id','time'])\n",
    "    selected_regimes = []\n",
    "    regime_id = 0\n",
    "    for caseid in tqdm(regime_list[np.all(regime_list[['S','D']]>0.5, axis=1)|np.all(regime_list[['S','Fd']]>0.5, axis=1)].index):\n",
    "        cfdf = cfdata.loc[caseid]\n",
    "        end_list = np.where((cfdf.iloc[1:]['regime']=='S')&(cfdf.iloc[:-1]['regime'].isin(['D','Fd'])))[0]\n",
    "        for end in end_list:\n",
    "            if len(cfdf.iloc[:end])>=9 and np.all(cfdf.iloc[end-9:end]['regime']==cfdf.iloc[end]['regime']):\n",
    "                start_list = np.where((cfdf['regime']==cfdf.iloc[end]['regime'])&(cfdf['time']<cfdf.iloc[end]['time']))[0]\n",
    "                if np.all(np.round(np.diff(start_list))<=1.5):\n",
    "                    start = start_list[0]\n",
    "                else:\n",
    "                    start = start_list[np.where(np.round(np.diff(start_list))>1.5)[0][-1]+1]\n",
    "                cf_regime = cfdf.iloc[start:end+1].copy()\n",
    "                cf_regime['regime_id'] = regime_id\n",
    "                regime_id += 1\n",
    "                selected_regimes.append(cf_regime)\n",
    "    selected_regimes = pd.concat(selected_regimes)\n",
    "    selected_regimes = selected_regimes[selected_regimes.groupby('regime_id')['a_follower'].transform('max')<0]\n",
    "    selected_regimes = selected_regimes.sort_values(by=['regime_id','time'])\n",
    "    selected_regimes = selected_regimes[(selected_regimes.groupby('regime_id')['dhw'].transform('first')-selected_regimes.groupby('regime_id')['dhw'].transform('last'))>0]\n",
    "\n",
    "    first = selected_regimes.groupby('regime_id')[['a_follower','a_leader','dhw','thw']].first()\n",
    "    last = selected_regimes.groupby('regime_id')[['a_follower','a_leader','dhw','thw']].last()\n",
    "\n",
    "    selected_regimes['time_start'] = selected_regimes.groupby('regime_id')['time'].transform('first')\n",
    "    selected_regimes['time'] = selected_regimes['time'] - selected_regimes['time_start']\n",
    "    selected_regimes['time_end'] = selected_regimes.groupby('regime_id')['time'].transform('last')\n",
    "    selected_regimes['order'] = selected_regimes.groupby('regime_id')['dhw'].transform('first')\n",
    "    selected_regimes = selected_regimes.sort_values(by=['time_end','order','time'], ascending=[False,True,True])\n",
    "    selected_regimes = selected_regimes.set_index('regime_id')\n",
    "    timestarts = np.linspace(0,10,len(selected_regimes.index.unique()))\n",
    "    for regimeid,timestart in zip(selected_regimes.index.unique(),timestarts):\n",
    "        selected_regimes.loc[regimeid,'time_start'] = timestart\n",
    "    selected_regimes['time'] = selected_regimes['time'] + selected_regimes['time_start']\n",
    "    selected_regimes = selected_regimes.reset_index()\n",
    "\n",
    "    return first, last, selected_regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_HH, last_HH, selected_regimes_HH = select_deceleration(Lyft_HH.set_index('case_id'), regime_list_HH.loc[Lyft_HH['case_id'].unique()])\n",
    "first_HA, last_HA, selected_regimes_HA = select_deceleration(Lyft_HA.set_index('case_id'), regime_list_HA.loc[Lyft_HA['case_id'].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4,figsize=(8.,1.1),gridspec_kw={'width_ratios':[1,1,0.25,1],'wspace':0.1})\n",
    "axes[2].axis('off')\n",
    "\n",
    "lines_HA = [line[['time','dhw']].values for _, line in selected_regimes_HA.groupby('regime_id')[['time','dhw']]]\n",
    "lc_HA = mpl.collections.LineCollection(lines_HA, color='tab:red', linewidth=0.15, alpha=0.25, rasterized=True)\n",
    "lines_HH = [line[['time','dhw']].values for _, line in selected_regimes_HH.groupby('regime_id')[['time','dhw']]]\n",
    "lc_HH = mpl.collections.LineCollection(lines_HH, color='tab:blue', linewidth=0.15, alpha=0.25, rasterized=True)\n",
    "\n",
    "axes[0].add_collection(lc_HH)\n",
    "axes[1].add_collection(lc_HA)\n",
    "\n",
    "for ax in [axes[0],axes[1]]:\n",
    "    ax.set_xlim([-0.1,12.1])\n",
    "    ax.set_ylim([0,52])\n",
    "\n",
    "axes[0].set_title('HH', fontsize=8, pad=0)\n",
    "axes[0].set_xlabel('Time (s)')\n",
    "axes[0].set_ylabel('Distance headway (m)')\n",
    "axes[1].set_title('HA', fontsize=8, pad=0)\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_yticklabels([])\n",
    "\n",
    "group = selected_regimes_HH.groupby('regime_id')\n",
    "axes[3].plot(group['time_end'].first(), group['v_follower'].first(), 'o', ms=1., fillstyle='none', mew=0.2, c='tab:blue', label='HH', rasterized=True)\n",
    "group = selected_regimes_HA.groupby('regime_id')\n",
    "axes[3].plot(group['time_end'].first(), group['v_follower'].first(), 'o', ms=1., fillstyle='none', mew=0.2, c='tab:red', label='HA', rasterized=True)\n",
    "axes[3].set_xlabel('Duration (s)')\n",
    "axes[3].set_ylabel('Initial follower speed (m/s)')\n",
    "axes[3].set_yticks([0,5,10,15])\n",
    "axes[3].legend(frameon=False, loc='lower center', bbox_to_anchor=(0.5, 0.95), fontsize=8, handletextpad=0.1, borderpad=0.1, labelspacing=0.1, ncol=2, columnspacing=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(figure_path+'reductionDHW.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_FD(cfdata): # Xiaopeng Li https://doi.org/10.1016/j.trb.2021.06.011\n",
    "    k = []\n",
    "    q = []\n",
    "    for regime in ['C','A','D','F']:\n",
    "        steady_cf = cfdata[cfdata['regime']==regime]\n",
    "        steady_cf = steady_cf[steady_cf.groupby('case_id').time.transform('count')>30].set_index('case_id')\n",
    "        # steady_cf['dhw'] = steady_cf['x_leader'] - steady_cf['x_follower']\n",
    "        steady_cf['dhw'] = steady_cf['dhw']/1000 # convert to km\n",
    "        steady_cf['x_follower'] = steady_cf['x_follower']/1000 # convert to km\n",
    "        for caseid in tqdm(steady_cf.index.unique()):\n",
    "            steady_cf_case = steady_cf.loc[caseid]\n",
    "            for splited_case in np.split(steady_cf_case, np.where(np.round(np.diff(steady_cf_case.time.values),1)!=0.1)[0]+1):\n",
    "                if len(splited_case) < 10 or splited_case['v_follower'].mean()>8:\n",
    "                    continue\n",
    "                else:\n",
    "                    splited_case['time'] = splited_case['time']/3600 # convert to hour\n",
    "                    area = np.trapz(splited_case['dhw'].values, splited_case['time'].values)\n",
    "                    k.append((splited_case['time'].max()-splited_case['time'].min())/area)\n",
    "                    q.append((splited_case['x_follower'].iloc[-1]-splited_case['x_follower'].iloc[0])/area)\n",
    "    return np.array(k), np.array(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, q = draw_FD(Lyft_HA)\n",
    "plt.scatter(k, q, s=1, alpha=0.4)\n",
    "k, q = draw_FD(Lyft_HH)\n",
    "plt.scatter(k, q, s=1, alpha=0.4)\n",
    "plt.xlim([0,250])\n",
    "plt.ylim([-10,4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
